{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 每個政治的url,2016/11/26~now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "import datetime\n",
    "import concurrent.futures\n",
    "from datetime import datetime, timedelta, date\n",
    "import json\n",
    "udn_url=[]\n",
    "\n",
    "_format = \"%Y/%m/%d\"\n",
    "d = datetime.strptime(\"2016/11/25\", _format) ##2016/11/25 00:00:00\n",
    "delta = timedelta(days = 1)\n",
    "today = datetime.strptime(date.today().strftime(_format), _format)\n",
    "while d <= today:\n",
    "    oldtime = d.strftime(_format)\n",
    "    resp = requests.get(\"https://udn.com/news/archive/2/6638/%s/1\"%oldtime) ##把時分秒去掉\n",
    "    soup = BeautifulSoup(resp.text,\"html5lib\")\n",
    "    selects = soup.select(\"div.pagelink > span.total\")\n",
    "    s = selects[0].text\n",
    "    r = re.findall(\"共 (.) 頁\",s)[0]\n",
    "    r = int(r)\n",
    "    print(r)\n",
    "    for pg in range(1,r+1):\n",
    "        URL = \"https://udn.com/news/archive/2/6638/{}/{}\".format(oldtime,pg)\n",
    "        udn_url.append(URL)\n",
    "    d += delta\n",
    "print(udn_url)\n",
    "with open(\"udn_url.txt\",\"w\") as f:\n",
    "    f.write(json.dumps(udn_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 爬每一個新聞的url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor \n",
    "with open(\"udn_url.txt\",\"r\") as f:\n",
    "    r = f.read()\n",
    "    \n",
    "udn_url = r.replace('\"','').replace(\"[\",\"\").replace(\"]\",\"\").split(\",\")\n",
    "def udn_news(url):\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.text,\"html5lib\")\n",
    "    selects = soup.select(\"tr > td > a\")\n",
    "    Domain = \"https://udn.com\"\n",
    "    list_url=[]\n",
    "    for s in selects :\n",
    "        if s.get(\"href\").startswith(\"/news/story/6656/\"):\n",
    "            u = s.get(\"href\")\n",
    "            list_url.append(Domain+u)\n",
    "    return list_url\n",
    "            \n",
    "list_newss=[]        \n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:\n",
    "    for data in executor.map(udn_news, udn_url):\n",
    "        print(data)\n",
    "        list_newss.extend(data)\n",
    "        \n",
    "with open(\"udn_everynews_url.txt\",\"w\") as f:\n",
    "    f.write(json.dumps(list_newss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 爬每個新聞標題、時間、內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "with open(\"udn_everynews_url.txt\",\"r\") as f:\n",
    "    r = f.read()\n",
    "udn_everynews_url = r.replace('\"','').replace(\"[\",\"\").replace(\"]\",\"\").split(\",\")\n",
    "\n",
    "def udn_everynews(url): \n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.text,\"html5lib\")\n",
    "    try:\n",
    "        \n",
    "        dic = {}\n",
    "        selects_title = soup.select(\"div#story_body_content > h1\")\n",
    "        dic[\"title\"] = selects_title[0].text\n",
    "\n",
    "        selects_time = soup.select(\"div.story_bady_info_author > span\")\n",
    "        dic[\"time\"] = selects_time[0].text\n",
    "        list_content=[]\n",
    "        selects_content = soup.select(\"div#story_body_content > p\")\n",
    "        for c in selects_content:\n",
    "            if len(c) != 0: #去除空值\n",
    "                list_content.append(c.text)\n",
    "        dic[\"content\"] = list_content\n",
    "        return dic\n",
    "    except:\n",
    "        return dic\n",
    "list_newsss = []    \n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=50) as executor:\n",
    "    for data1 in executor.map(udn_everynews, udn_everynews_url):\n",
    "        list_newsss.append(data1)\n",
    "df = pd.DataFrame(list_newsss)\n",
    "df.to_csv(\"udn_news.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 時間格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, date\n",
    "_format = \"%Y/%m/%d\"\n",
    "d = datetime.strptime(\"2016/11/25\", _format) ##2016/11/25 00:00:00\n",
    "delta = timedelta(days = 1)\n",
    "while d <= datetime.strptime(date.today().strftime(_format), _format): ##用striftime轉換date.today()成字串，再用轉成strptime比較大小\n",
    "    print(d.strftime(_format)) ##把後面的小時、分鐘、秒去掉\n",
    "    d += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-25\n",
      "2017-11-25 00:00:00\n",
      "2016-11-24 00:00:00\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta, date\n",
    "_format = \"%Y/%m/%d\"\n",
    "a = date.today()\n",
    "b = datetime.strptime(date.today().strftime(_format), _format)\n",
    "c = datetime.strptime(\"2016/11/24\", _format)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "# print(a > b) ###所以說要用datetime.strptime轉換成時間格式才能比大小\n",
    "print(b > c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = datetime.datetime.strptime(\"2016/11/24\", \"%Y/%m/%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016/11/24'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date.strftime(\"%Y/%m/%d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
